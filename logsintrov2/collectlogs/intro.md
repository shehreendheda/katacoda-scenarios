To start managing your logs in Datadog, you have to first configure log collection. And, depending on the logs source, Datadog has OOTB integrations with integration pipelines that can efficiently process your logs after collection. In this activity, you will complete the following steps to configure log collection and integrations pipleines for a Flask application supported by NGINX, Redis, an API, and a thinker microservice.

1. Preparing the Environment
2. Configuring the Datadog Agent for Log Collection
3. Viewing logs in the Log Explorer
4. Using the Source Tag to Enable Integration Pipelines
4. Using the Service Tag to Correlate Metrics, Traces, and Logs
5. Viewing Correlated Metrics, Traces, and Logs

When you are ready to continute, click **Start Scenario**.